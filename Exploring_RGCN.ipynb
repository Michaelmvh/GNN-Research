{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m-Gjz-IVobyy",
        "jqBB4RCyuxXl",
        "bisPoWonsX3R"
      ],
      "gpuType": "T4",
      "mount_file_id": "1YyO_cP-xT5o2vQVDs182RzjoLa6P-jOU",
      "authorship_tag": "ABX9TyMyA5/L6NcLiIGua5b5Z85b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michaelmvh/bozdag-research-GNN/blob/main/Exploring_RGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RGCN Link Prediction Example\n",
        "\n",
        "Source: [PyTorch Geometric Examples: RGCN Link Prediction](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn_link_pred.py)"
      ],
      "metadata": {
        "id": "koZtpsgRCikT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "m-Gjz-IVobyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h20c9kHqy8o_",
        "outputId": "f49aa08e-ee36-4476-b3bc-6807c1d1ea62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "saBRYyzloDhs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.models import GCN\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import from_networkx\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.loader import DataLoader\n",
        "import os.path as osp\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.datasets import RelLinkPredDataset\n",
        "from torch_geometric.nn import GAE, RGCNConv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "w2WkIl8dsnGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "bhZ5uv2ZpwSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThSF9tbpspFC",
        "outputId": "e2810f55-d858-4072-f7a0-f5f0d496109a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "7R0HOp8duuxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'RLPD')\n",
        "# path = osp.curdir\n",
        "# dataset = RelLinkPredDataset(path, 'FB15k-237')\n",
        "# data = dataset[0].to(device)"
      ],
      "metadata": {
        "id": "Wwxg8LjJwBod"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import RelLinkPredDataset\n",
        "from torch_geometric.loader import DataLoader  # Use PyG's DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LinkPredDataset(Dataset):\n",
        "    def __init__(self, edge_index, edge_type):\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_type = edge_type\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.edge_index.size(1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.edge_index[:, idx], self.edge_type[idx]\n",
        "\n",
        "# Load the dataset\n",
        "path = osp.curdir  # Or your desired path\n",
        "dataset = RelLinkPredDataset(path, 'FB15k-237')\n",
        "data = dataset[0].to(device)\n",
        "\n",
        "# Create train and test/validation datasets for edges\n",
        "train_dataset = LinkPredDataset(data.train_edge_index, data.train_edge_type)\n",
        "# Assuming you want to combine validation and test for evaluation\n",
        "val_test_edge_index = torch.cat([data.valid_edge_index, data.test_edge_index], dim=1)\n",
        "val_test_edge_type = torch.cat([data.valid_edge_type, data.test_edge_type])\n",
        "val_test_dataset = LinkPredDataset(val_test_edge_index, val_test_edge_type)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_test_loader = DataLoader(val_test_dataset, batch_size=128, shuffle=False)  # No need to shuffle for evaluation"
      ],
      "metadata": {
        "id": "sfNhNU11tVLt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model"
      ],
      "metadata": {
        "id": "jqBB4RCyuxXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
        "        super().__init__()\n",
        "        self.node_emb = Parameter(torch.empty(num_nodes, hidden_channels)) # Treat x as learnable param\n",
        "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
        "                              num_bases=5)\n",
        "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
        "                              num_bases=5)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.node_emb) # Initialize x with xavier uniform distribution\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, edge_index, edge_type):\n",
        "        x = self.node_emb\n",
        "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "        return x"
      ],
      "metadata": {
        "id": "R2vXYGG2uG4V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistMultDecoder(torch.nn.Module):\n",
        "    def __init__(self, num_relations, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.rel_emb = Parameter(torch.empty(num_relations, hidden_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
        "\n",
        "    def forward(self, z, edge_index, edge_type):\n",
        "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
        "        rel = self.rel_emb[edge_type]\n",
        "        return torch.sum(z_src * rel * z_dst, dim=1)"
      ],
      "metadata": {
        "id": "4JCHI-DjuG-a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def negative_sampling(edge_index, num_nodes):\n",
        "    # Sample edges by corrupting either the subject or the object of each edge.\n",
        "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(), ),\n",
        "                                              device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(), ),\n",
        "                                              device=neg_edge_index.device)\n",
        "    return neg_edge_index"
      ],
      "metadata": {
        "id": "WWqgMfAKuHJu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Train/Test"
      ],
      "metadata": {
        "id": "FvK6FyjMu1y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, optimizer, train_loader):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "\n",
        "#     for batch_idx, (edge_index, edge_type) in enumerate(train_loader):\n",
        "#       z = model.encode(data.edge_index, data.edge_type)\n",
        "\n",
        "#       pos_out = model.decode(z, edge_index, edge_type)\n",
        "\n",
        "#       neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
        "#       neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
        "\n",
        "#       out = torch.cat([pos_out, neg_out])\n",
        "#       gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
        "#       cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "#       reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
        "#       loss = cross_entropy_loss + 1e-2 * reg_loss\n",
        "\n",
        "#     loss.backward()\n",
        "#     torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "#     optimizer.step()\n",
        "\n",
        "#     return float(loss)"
      ],
      "metadata": {
        "id": "QqbJaIzLuQfK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_loader, data): # Pass the full data object and device\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    # --- Encode the full graph ONCE before the loop ---\n",
        "    # This is still a potential memory bottleneck for very large graphs.\n",
        "    # For truly large graphs, consider neighbor sampling techniques (e.g., NeighborLoader).\n",
        "    with torch.no_grad(): # No need to track gradients for encoding if done once\n",
        "         z = model.encode(data.edge_index, data.edge_type)\n",
        "    # ----------------------------------------------------\n",
        "\n",
        "    for batch_idx, (batch_edge_index, batch_edge_type) in enumerate(train_loader):\n",
        "        batch_edge_index = batch_edge_index.T # Fix this later on\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # --- Use pre-computed full graph embeddings 'z' ---\n",
        "        # Decode positive edges from the current batch\n",
        "        pos_out = model.decode(z, batch_edge_index, batch_edge_type)\n",
        "\n",
        "        # Negative sampling based on the edges in the current batch\n",
        "        # Note: negative_sampling function needs modification or replacement\n",
        "        # if you want batch-specific negative sampling.\n",
        "        # Current negative_sampling samples from the *entire* training set.\n",
        "        # For simplicity here, we'll sample globally but decode using batch indices.\n",
        "        # A more advanced approach would sample negatives only involving nodes in the batch.\n",
        "\n",
        "        # Sample negatives globally (as in original code)\n",
        "        neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes) # Sample globally\n",
        "        neg_edge_index = neg_edge_index.to(device)\n",
        "\n",
        "        # Select corresponding global edge types for the sampled negative edges\n",
        "        # This is an approximation; ideally, you'd know the types for corrupted edges.\n",
        "        # If negative_sampling corrupts based on existing edges, we might reuse types.\n",
        "        # Let's assume we need to select types corresponding to the *indices* of the\n",
        "        # original edges from which negatives were derived, which is complex.\n",
        "        # A simpler (though less precise) approach might be to randomly assign types\n",
        "        # or use the types corresponding to the *original* positive edges being corrupted.\n",
        "        # Given the original `negative_sampling` structure, linking back type is hard.\n",
        "        # Let's stick to the original logic's structure for now, using global train_edge_type:\n",
        "        # This part might need refinement depending on how negative sampling should interact with types.\n",
        "        neg_out = model.decode(z, neg_edge_index, data.train_edge_type) # Still using global types\n",
        "\n",
        "        # --- Combine positive and negative outputs for loss calculation ---\n",
        "        out = torch.cat([pos_out, neg_out])\n",
        "        gt = torch.cat([\n",
        "            torch.ones_like(pos_out),\n",
        "            torch.zeros_like(neg_out)\n",
        "        ]).to(device) # Ensure ground truth is on the correct device\n",
        "\n",
        "        cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "\n",
        "        # Regularization (consider applying only to parameters used in the batch if needed)\n",
        "        # Using the full 'z' means full regularization is applied based on all node embeddings.\n",
        "        reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
        "        loss = cross_entropy_loss + 1e-2 * reg_loss\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches # Return average loss per batch"
      ],
      "metadata": {
        "id": "WPTWfhT7acfv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, val_test_loader, data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.edge_index, data.edge_type)\n",
        "\n",
        "    valid_mrr = compute_mrr(z, data.valid_edge_index, data.valid_edge_type)\n",
        "    test_mrr = compute_mrr(z, data.test_edge_index, data.test_edge_type)\n",
        "\n",
        "    return valid_mrr, test_mrr"
      ],
      "metadata": {
        "id": "-3hO6gbguQm6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_rank(ranks):\n",
        "    # fair ranking prediction as the average\n",
        "    # of optimistic and pessimistic ranking\n",
        "    true = ranks[0]\n",
        "    optimistic = (ranks > true).sum() + 1\n",
        "    pessimistic = (ranks >= true).sum()\n",
        "    return (optimistic + pessimistic).float() * 0.5"
      ],
      "metadata": {
        "id": "JuKlfNKruQub"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_mrr(z, edge_index, edge_type):\n",
        "    ranks = []\n",
        "    for i in tqdm(range(edge_type.numel())):\n",
        "        (src, dst), rel = edge_index[:, i], edge_type[i]\n",
        "\n",
        "        # Try all nodes as tails, but delete true triplets:\n",
        "        tail_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
        "        for (heads, tails), types in [\n",
        "            (data.train_edge_index, data.train_edge_type),\n",
        "            (data.valid_edge_index, data.valid_edge_type),\n",
        "            (data.test_edge_index, data.test_edge_type),\n",
        "        ]:\n",
        "            tail_mask[tails[(heads == src) & (types == rel)]] = False\n",
        "\n",
        "        tail = torch.arange(data.num_nodes)[tail_mask]\n",
        "        tail = torch.cat([torch.tensor([dst]), tail])\n",
        "        head = torch.full_like(tail, fill_value=src)\n",
        "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
        "        eval_edge_type = torch.full_like(tail, fill_value=rel)\n",
        "\n",
        "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
        "        rank = compute_rank(out)\n",
        "        ranks.append(rank)\n",
        "\n",
        "        # Try all nodes as heads, but delete true triplets:\n",
        "        head_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
        "        for (heads, tails), types in [\n",
        "            (data.train_edge_index, data.train_edge_type),\n",
        "            (data.valid_edge_index, data.valid_edge_type),\n",
        "            (data.test_edge_index, data.test_edge_type),\n",
        "        ]:\n",
        "            head_mask[heads[(tails == dst) & (types == rel)]] = False\n",
        "\n",
        "        head = torch.arange(data.num_nodes)[head_mask]\n",
        "        head = torch.cat([torch.tensor([src]), head])\n",
        "        tail = torch.full_like(head, fill_value=dst)\n",
        "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
        "        eval_edge_type = torch.full_like(head, fill_value=rel)\n",
        "\n",
        "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
        "        rank = compute_rank(out)\n",
        "        ranks.append(rank)\n",
        "\n",
        "    return (1. / torch.tensor(ranks, dtype=torch.float)).mean()"
      ],
      "metadata": {
        "id": "8vpa2L1yuQ2e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run model"
      ],
      "metadata": {
        "id": "Kpwpb8zkvROo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GAE(\n",
        "    RGCNEncoder(data.num_nodes, 500, dataset.num_relations),\n",
        "    DistMultDecoder(dataset.num_relations, 500),\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "V7mMDQcDTznJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times = []\n",
        "for epoch in range(1, 200):\n",
        "    start = time.time()\n",
        "    loss = train(model, optimizer, train_loader, data)\n",
        "    print(f'Epoch: {epoch:05d}, Loss: {loss:.4f}')\n",
        "    if (epoch % 100) == 0:\n",
        "        valid_mrr, test_mrr = test(model, val_test_loader, data)\n",
        "        print(f'Val MRR: {valid_mrr:.4f}, Test MRR: {test_mrr:.4f}')\n",
        "    times.append(time.time() - start)\n",
        "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
      ],
      "metadata": {
        "id": "JRM5lyPiEwrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3adb1ca8-9762-4c31-dc88-df23bdd1254a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00001, Loss: 0.6705\n",
            "Epoch: 00002, Loss: 0.6661\n",
            "Epoch: 00003, Loss: 0.6648\n",
            "Epoch: 00004, Loss: 0.6649\n",
            "Epoch: 00005, Loss: 0.6648\n",
            "Epoch: 00006, Loss: 0.6647\n",
            "Epoch: 00007, Loss: 0.6646\n",
            "Epoch: 00008, Loss: 0.6645\n",
            "Epoch: 00009, Loss: 0.6650\n",
            "Epoch: 00010, Loss: 0.6645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "bisPoWonsX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, optimizer, train_loader, data): # Pass the full data object and device\n",
        "model.train()\n",
        "total_loss = 0\n",
        "num_batches = 0\n",
        "\n",
        "# --- Encode the full graph ONCE before the loop ---\n",
        "# This is still a potential memory bottleneck for very large graphs.\n",
        "# For truly large graphs, consider neighbor sampling techniques (e.g., NeighborLoader).\n",
        "# with torch.no_grad(): # No need to track gradients for encoding if done once\n",
        "      # z = model.encode(data.edge_index, data.edge_type)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "for batch_idx, (batch_edge_index, batch_edge_type) in enumerate(train_loader):\n",
        "    # print(batch_idx)\n",
        "    optimizer.zero_grad()\n",
        "    batch_edge_index = batch_edge_index.T\n",
        "\n",
        "    # --- Use pre-computed full graph embeddings 'z' ---\n",
        "    # Decode positive edges from the current batch\n",
        "    print(z.shape)\n",
        "    print(batch_edge_index.shape)\n",
        "    # print(batch_edge_type.shape)\n",
        "    pos_out = model.decode(z, batch_edge_index, batch_edge_type)\n",
        "    print(\"Success: \")\n",
        "    print(pos_out)\n",
        "    break\n",
        "    # Negative sampling based on the edges in the current batch\n",
        "    # Note: negative_sampling function needs modification or replacement\n",
        "    # if you want batch-specific negative sampling.\n",
        "    # Current negative_sampling samples from the *entire* training set.\n",
        "    # For simplicity here, we'll sample globally but decode using batch indices.\n",
        "    # A more advanced approach would sample negatives only involving nodes in the batch.\n",
        "\n",
        "    # Sample negatives globally (as in original code)\n",
        "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes) # Sample globally\n",
        "    neg_edge_index = neg_edge_index.to(device)\n",
        "\n",
        "    # Select corresponding global edge types for the sampled negative edges\n",
        "    # This is an approximation; ideally, you'd know the types for corrupted edges.\n",
        "    # If negative_sampling corrupts based on existing edges, we might reuse types.\n",
        "    # Let's assume we need to select types corresponding to the *indices* of the\n",
        "    # original edges from which negatives were derived, which is complex.\n",
        "    # A simpler (though less precise) approach might be to randomly assign types\n",
        "    # or use the types corresponding to the *original* positive edges being corrupted.\n",
        "    # Given the original `negative_sampling` structure, linking back type is hard.\n",
        "    # Let's stick to the original logic's structure for now, using global train_edge_type:\n",
        "    # This part might need refinement depending on how negative sampling should interact with types.\n",
        "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type) # Still using global types\n",
        "\n",
        "    # --- Combine positive and negative outputs for loss calculation ---\n",
        "    out = torch.cat([pos_out, neg_out])\n",
        "    gt = torch.cat([\n",
        "        torch.ones_like(pos_out),\n",
        "        torch.zeros_like(neg_out)\n",
        "    ]).to(device) # Ensure ground truth is on the correct device\n",
        "\n",
        "    cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "\n",
        "    # Regularization (consider applying only to parameters used in the batch if needed)\n",
        "    # Using the full 'z' means full regularization is applied based on all node embeddings.\n",
        "    reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
        "    loss = cross_entropy_loss + 1e-2 * reg_loss\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += float(loss)\n",
        "    num_batches += 1\n",
        "\n",
        "print(f\"Loss: {total_loss}, batches: {num_batches} Avg Loss: {total_loss/(1+num_batches)}\")\n",
        "# return total_loss / num_batches # Return average loss per batch"
      ],
      "metadata": {
        "id": "IyPXMQ8FppzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel.shape"
      ],
      "metadata": {
        "id": "gNSBTeIdsz8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_src, z_dst = z[edge_index.T[0]], z[edge_index.T[1]]"
      ],
      "metadata": {
        "id": "-zBK3Txsu5p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(z_src.shape)\n",
        "print(z_dst.shape)\n",
        "print((z_src * z_dst).shape)"
      ],
      "metadata": {
        "id": "eMz0IWLpgXMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.decoder.rel_emb.shape"
      ],
      "metadata": {
        "id": "0BEglk4dkTPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (batch_edge_index, batch_edge_type) in enumerate(train_loader):\n",
        "  print(batch_edge_index.shape)\n",
        "  print(batch_edge_index[0].shape)\n",
        "  print(z[batch_edge_index[0]].shape)\n",
        "  print(batch_edge_type.shape)\n",
        "  print(model.decoder.rel_emb[batch_edge_type].shape)\n",
        "  print(z[batch_edge_index].shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "AIs-t5Zvkh-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(z_src * z_dst).shape"
      ],
      "metadata": {
        "id": "yqzvWFeAvtO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel.T.shape"
      ],
      "metadata": {
        "id": "PH2VH1ZkvvBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = z_src * rel[0] * z_dst"
      ],
      "metadata": {
        "id": "edMVc_lWwWm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "id": "BdypwBBmwhu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(test, dim=1).shape"
      ],
      "metadata": {
        "id": "H9x_0HUXz2DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_relations"
      ],
      "metadata": {
        "id": "8izwO4Ri0Gpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FMg1lEp0QgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}