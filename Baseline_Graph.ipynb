{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m-Gjz-IVobyy",
        "w2WkIl8dsnGk",
        "-PoCD1jDdBXe",
        "ZcdToTqRtdnq"
      ],
      "toc_visible": true,
      "mount_file_id": "1QmVg9ANbUwpZ1uf8_1zWpSKBIevzwXxk",
      "authorship_tag": "ABX9TyOBhOfTV0JHOJsRsWr94ERj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michaelmvh/bozdag-research-GNN/blob/main/Baseline_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "m-Gjz-IVobyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h20c9kHqy8o_",
        "outputId": "0264deae-db64-49fe-d4d8-86dce3134a65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "saBRYyzloDhs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.models import GCN\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import from_networkx\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "w2WkIl8dsnGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "bhZ5uv2ZpwSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_location = \"/content/drive/MyDrive/Colab Notebooks/Bozdag Research/Data/ChChSe-Decagon_polypharmacy.csv\""
      ],
      "metadata": {
        "id": "wVG4Ms5aqGI9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ofonEHDVso6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThSF9tbpspFC",
        "outputId": "d0b18aea-643f-4a03-aa60-7953f9e2589d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "AWhpeBQxoe2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph_from_edge_list(file_path:str, ignore_edge_type: bool = True):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return nx.from_pandas_edgelist(df=df, source='# STITCH 1', target='STITCH 2', edge_attr= None if ignore_edge_type else True)\n",
        "\n",
        "nx_data = load_graph_from_edge_list(graph_location)\n",
        "print(nx_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLnMqt4l10vT",
        "outputId": "78543804-4e20-4130-bd7a-6c3b5809835e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 645 nodes and 63473 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will print 2x as many edges as networkx representation because of how\n",
        "# (un)directed edges are handled\n",
        "data = from_networkx(nx_data)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LozGMs2XBjxW",
        "outputId": "fb40052a-94f3-4292-8f3f-a6f5e5236ffb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 126946], num_nodes=645)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset information"
      ],
      "metadata": {
        "id": "vP_miC2nohdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_graph_info(G: nx.Graph):\n",
        "  clustering_coeff = nx.average_clustering(G)\n",
        "\n",
        "  def avg_degree(G:nx.graph):\n",
        "    return nx.number_of_edges(G)/nx.number_of_nodes(G)*2\n",
        "\n",
        "  print(f\"Average Degree: {avg_degree(G)}\\nClustering Coefficient: {clustering_coeff}\")\n",
        "  # nx.draw(nx_data)\n",
        "  nx.draw(G)\n",
        "\n",
        "  # print_graph_info(nx_data)"
      ],
      "metadata": {
        "id": "Xl_QwQc4ohkZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Node Features"
      ],
      "metadata": {
        "id": "7OWgktR5TCJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding"
      ],
      "metadata": {
        "id": "Z8jQmL_esLfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = nx_data.number_of_nodes()\n",
        "data.x = torch.eye(num_nodes)"
      ],
      "metadata": {
        "id": "ImBCz0eqTL_7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "zphFEv2fTlSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4c4312-1381-4345-dcc5-f7191b3b09cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 126946], num_nodes=645, x=[645, 645])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/test/val split"
      ],
      "metadata": {
        "id": "RanKhULlTzgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traian, val, test split\n",
        "transform = RandomLinkSplit(\n",
        "    is_undirected=True,\n",
        "    add_negative_train_samples=True,\n",
        "    split_labels=True)\n",
        "train_data, val_data, test_data = transform(data)"
      ],
      "metadata": {
        "id": "GLQ222hvT2zH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train: \",train_data)\n",
        "print(\"Val: \",val_data)\n",
        "print(\"Test: \",test_data)"
      ],
      "metadata": {
        "id": "aXt27g0kwXTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f4a734-815e-41ab-ec09-5ddf83053430"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  Data(edge_index=[2, 88864], num_nodes=645, x=[645, 645], pos_edge_label=[44432], pos_edge_label_index=[2, 44432], neg_edge_label=[44432], neg_edge_label_index=[2, 44432])\n",
            "Val:  Data(edge_index=[2, 88864], num_nodes=645, x=[645, 645], pos_edge_label=[6347], pos_edge_label_index=[2, 6347], neg_edge_label=[6347], neg_edge_label_index=[2, 6347])\n",
            "Test:  Data(edge_index=[2, 101558], num_nodes=645, x=[645, 645], pos_edge_label=[12694], pos_edge_label_index=[2, 12694], neg_edge_label=[12694], neg_edge_label_index=[2, 12694])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Network"
      ],
      "metadata": {
        "id": "yblimajsuTrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "PBE7GPGNLGLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, out_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # Embeddings\n",
        "\n",
        "# Model parameters\n",
        "input_dim = train_data.x.size(1)\n",
        "hidden_dim = input_dim * 2\n",
        "output_dim = 32  # Embedding size\n",
        "\n",
        "model = GCN(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JRM5lyPiEwrm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Decoder"
      ],
      "metadata": {
        "id": "6kMZ7UWxVqwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(z, edge_index):\n",
        "    value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
        "    return value"
      ],
      "metadata": {
        "id": "5EWgGpneVqB9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Training"
      ],
      "metadata": {
        "id": "1U-vvcGiLIJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Compute node embeddings using (only) the training graph.\n",
        "    z = model(data.x, data.pos_edge_label_index)\n",
        "\n",
        "    # Positive edge predictions.\n",
        "    pos_pred = torch.sigmoid(decode(z, data.pos_edge_label_index))\n",
        "    # Negative edge predictions.\n",
        "    neg_pred = torch.sigmoid(decode(z, data.neg_edge_label_index))\n",
        "\n",
        "    # Use binary cross-entropy loss.\n",
        "    loss = F.binary_cross_entropy(pos_pred, torch.ones_like(pos_pred)) + \\\n",
        "           F.binary_cross_entropy(neg_pred, torch.zeros_like(neg_pred))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "0Yxp66qpLJiG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Testing"
      ],
      "metadata": {
        "id": "TSiMJKYZaymf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data, return_predictions=False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(data.x, data.edge_index)  # Note: use full graph for message passing.\n",
        "\n",
        "    pos_pred = decode(z, data.pos_edge_label_index)\n",
        "    neg_pred = decode(z, data.neg_edge_label_index)\n",
        "\n",
        "\n",
        "    if(return_predictions):\n",
        "      predictions = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
        "      labels = torch.cat([torch.ones(pos_pred.size(0)), torch.zeros(neg_pred.size(0))]).cpu().numpy()\n",
        "      return predictions, labels\n",
        "    else:\n",
        "      pos_score = torch.sigmoid(pos_pred)\n",
        "      neg_score = torch.sigmoid(neg_pred)\n",
        "      return ((pos_score > 0.5).sum() + (neg_score < 0.5).sum()) / (pos_score.size(0) + neg_score.size(0))"
      ],
      "metadata": {
        "id": "f2u3qiPvayzg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "def evaluation(predictions, labels):\n",
        "  return {\n",
        "    \"Accuracy\": accuracy_score(predictions, labels),\n",
        "    \"Precision\": precision_score(predictions, labels),\n",
        "    \"Recall\": recall_score(predictions, labels),\n",
        "    \"F1\": f1_score(labels, predictions),\n",
        "    \"AUC\": roc_auc_score(labels, predictions)\n",
        "  }"
      ],
      "metadata": {
        "id": "r1hEwL2dU0Tb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 101):  # Train for 100 epochs\n",
        "    loss = train(model, train_data, optimizer)\n",
        "    if epoch%10==0:\n",
        "      val_acc = test(model, val_data)\n",
        "      print(f'Epoch: {epoch}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebNtgR6iYCkL",
        "outputId": "4b4e21ae-b297-4c8f-abfb-ad423b809ebc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 1.3461, Val Acc: 0.5000\n",
            "Epoch: 20, Loss: 1.2521, Val Acc: 0.5315\n",
            "Epoch: 30, Loss: 1.1802, Val Acc: 0.6321\n",
            "Epoch: 40, Loss: 1.1089, Val Acc: 0.5942\n",
            "Epoch: 50, Loss: 1.0656, Val Acc: 0.5691\n",
            "Epoch: 60, Loss: 1.0381, Val Acc: 0.5274\n",
            "Epoch: 70, Loss: 1.0289, Val Acc: 0.5144\n",
            "Epoch: 80, Loss: 1.0272, Val Acc: 0.4844\n",
            "Epoch: 90, Loss: 1.0276, Val Acc: 0.4693\n",
            "Epoch: 100, Loss: 1.0273, Val Acc: 0.4821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels = test(model, test_data, return_predictions=True)\n",
        "metrics_dict = evaluation(predictions, labels)\n",
        "print(f'Test Metrics:\\n {metrics_dict}')"
      ],
      "metadata": {
        "id": "pmWnV8CBWMfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "890e23c1-5d2d-4f5e-e3f3-4a749707c6e0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-24c5f9049b84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Metrics:\\n {metrics_dict}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-c544cd7f2a5c>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   return {\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive - Example Models to compare to later"
      ],
      "metadata": {
        "id": "-PoCD1jDdBXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, out_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # Embeddings\n",
        "\n",
        "\n",
        "def decode(z, edge_index):\n",
        "    \"\"\"Compute scores for each edge pair using dot product\"\"\"\n",
        "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model parameters\n",
        "input_dim = train_data.x.size(1)\n",
        "hidden_dim = 64\n",
        "output_dim = 32  # Embedding size\n",
        "\n",
        "model = GCN(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "train_data = train_data.to(device)\n",
        "\n",
        "def train(train_data: Tensor):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z = model(train_data.x, train_data.edge_index)  # Compute node embeddings\n",
        "\n",
        "    # Compute scores for positive edges\n",
        "    pos_score = torch.sigmoid(decode(z, train_data.pos_edge_label_index))\n",
        "    pos_loss = -torch.log(pos_score + 1e-15).mean()\n",
        "\n",
        "    # Compute scores for negative edges\n",
        "    neg_score = torch.sigmoid(decode(z, train_data.neg_edge_label_index))\n",
        "    neg_loss = -torch.log(1 - neg_score + 1e-15).mean()\n",
        "\n",
        "    # Combine the losses\n",
        "    loss = pos_loss + neg_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "gris0DCaA24l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "\n",
        "    z = model(data.x, data.edge_index)  # Get embeddings\n",
        "\n",
        "    pos_score = torch.sigmoid(decode(z, data.pos_edge_label_index))\n",
        "    neg_score = torch.sigmoid(decode(z, data.neg_edge_label_index))\n",
        "\n",
        "    # Compute accuracy\n",
        "    acc = ((pos_score > 0.5).sum() + (neg_score < 0.5).sum()) / (pos_score.size(0) + neg_score.size(0))\n",
        "\n",
        "    return acc.item()\n",
        "\n",
        "for epoch in range(1, 101):  # Train for 100 epochs\n",
        "    loss = train(train_data)\n",
        "    if epoch%10==0:\n",
        "      val_acc = test(val_data)\n",
        "      print(f'Epoch: {epoch}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "test_acc = test(test_data)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo_yVa0aA32X",
        "outputId": "6e40d557-ad80-4ffb-90b0-90d432de8f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.9779, Val Acc: 0.7149\n",
            "Epoch: 20, Loss: 0.9778, Val Acc: 0.7129\n",
            "Epoch: 30, Loss: 0.9796, Val Acc: 0.7146\n",
            "Epoch: 40, Loss: 0.9770, Val Acc: 0.7155\n",
            "Epoch: 50, Loss: 0.9769, Val Acc: 0.7147\n",
            "Epoch: 60, Loss: 0.9799, Val Acc: 0.7155\n",
            "Epoch: 70, Loss: 0.9817, Val Acc: 0.7158\n",
            "Epoch: 80, Loss: 0.9766, Val Acc: 0.7152\n",
            "Epoch: 90, Loss: 0.9802, Val Acc: 0.7158\n",
            "Epoch: 100, Loss: 0.9878, Val Acc: 0.7149\n",
            "Test Accuracy: 0.7168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCOmtZM2A6qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAE Example"
      ],
      "metadata": {
        "id": "ZcdToTqRtdnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(data.num_features, 128)\n",
        "        self.conv2 = GCNConv(128, 64)\n",
        "\n",
        "    def encode(self,data):\n",
        "        x = self.conv1(data.x, data.train_pos_edge_index) # convolution 1\n",
        "        x = x.relu()\n",
        "        return self.conv2(x, data.train_pos_edge_index) # convolution 2\n",
        "\n",
        "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
        "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
        "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product\n",
        "        return logits\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t() # get adj NxN\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list"
      ],
      "metadata": {
        "id": "1QLgLnvfr3-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "q9r6fZnFti0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import negative_sampling\n",
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    # returns a tensor:\n",
        "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
        "    # and the number of zeros is equal to the length of neg_edge_index\n",
        "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
        "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_edge_index.size(1)] = 1.\n",
        "    return link_labels\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "\n",
        "    # neg_edge_index = negative_sampling(\n",
        "    #     edge_index=data.train_pos_edge_index, #positive edges\n",
        "    #     num_nodes=data.num_nodes, # number of nodes\n",
        "    #     num_neg_samples=data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z = model.encode() #encode\n",
        "    link_logits = model.decode(z, data.train_pos_edge_index, data.edge_label) # decode\n",
        "\n",
        "    link_labels = get_link_labels(data.train_pos_edge_index, data.edge_label)\n",
        "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    perfs = []\n",
        "    for prefix in [\"val\", \"test\"]:\n",
        "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
        "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
        "\n",
        "        z = model.encode() # encode train\n",
        "        link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "\n",
        "        link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
        "\n",
        "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score\n",
        "    return perfs\n"
      ],
      "metadata": {
        "id": "XxbygEiVtmmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_val_perf = test_perf = 0\n",
        "for epoch in range(1, 101):\n",
        "    train_loss = train(train_data)\n",
        "    val_perf, tmp_test_perf = test(test_data)\n",
        "    if val_perf > best_val_perf:\n",
        "        best_val_perf = val_perf\n",
        "        test_perf = tmp_test_perf\n",
        "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "    if epoch % 10 == 0:\n",
        "        print(log.format(epoch, train_loss, best_val_perf, test_perf))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "oF20sS7Jtm1J",
        "outputId": "3837392b-d039-4bc3-cd94-4e1fcd809422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GlobalStorage' object has no attribute 'train_pos_edge_index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b628ab7e2046>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_perf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_test_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_perf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_perf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-fb648a8f1497>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mlink_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_pos_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-256dc3be6228>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_pos_edge_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convolution 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_pos_edge_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convolution 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{key}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             ) from None\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_pos_edge_index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(z, edge_index):\n",
        "    # Compute the inner product for each edge pair\n",
        "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
        "\n",
        "def train_link_pred(train_data: Tensor):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(train_data.x, train_data.edge_index)\n",
        "    # Get scores for positive and negative edges\n",
        "    pos_score = decode(z, train_data.pos_edge_index)\n",
        "    neg_score = decode(z, train_data.neg_edge_index)\n",
        "    # Use binary cross-entropy loss, for instance\n",
        "    pos_loss = -torch.log(torch.sigmoid(pos_score) + 1e-15).mean()\n",
        "    neg_loss = -torch.log(1 - torch.sigmoid(neg_score) + 1e-15).mean()\n",
        "    loss = pos_loss + neg_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "b7PNflVp602n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(mask):\n",
        "    model.eval()  # In evaluation mode, dropout is deactivated\n",
        "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "    correct = pred[mask].eq(data.y[mask]).sum().item()\n",
        "    acc = correct / mask.sum().item()\n",
        "    return acc\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_link_pred(train_data)\n",
        "    train_acc = test(data.train_mask)\n",
        "    val_acc = test(data.val_mask)\n",
        "    print(f'Epoch: {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sSWAXCCn1cwT",
        "outputId": "30b99fb1-3a8a-4cb6-ddf4-94dd15aa51c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GlobalStorage' object has no attribute 'pos_edge_index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-449f25edc1ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_link_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-29e3e2fa7c3c>\u001b[0m in \u001b[0;36mtrain_link_pred\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get scores for positive and negative edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpos_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mneg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Use binary cross-entropy loss, for instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{key}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             ) from None\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'pos_edge_index'"
          ]
        }
      ]
    }
  ]
}